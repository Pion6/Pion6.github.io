<!DOCTYPE html>
<html lang=zh-CN>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:description" content="Pion6的博客">
    <meta property="og:type" content="website">
    <meta name="description" content="Pion6的博客">
    <meta name="keyword"  content="Pion6的博客">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        读点论文 - Pion6日常
        
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/aircloud.css">

    
<link rel="stylesheet" href="/css/gitment.css">

    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_28hi1hpxx24.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>

    









<meta name="generator" content="Hexo 7.1.1"></head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 我与我周旋久,宁作我 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>Xiaoxu Lin</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/collect/">
                    <i class="iconfont icon-shoucang1"></i>
                    <span>收藏</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Tree-of-Thoughts-Deliberate-Problem-Solving-with-Large-Language-Models"><span class="toc-text">Tree of Thoughts: Deliberate Problem Solving with Large Language Models</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E7%AB%A0%E4%BF%A1%E6%81%AF"><span class="toc-text">文章信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E7%9B%AE%E7%9A%84%E5%8F%8A%E7%BB%93%E8%AE%BA"><span class="toc-text">背景目的及结论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-text">背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E7%9A%84"><span class="toc-text">目的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-text">结论</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C%E4%B8%8E%E8%AE%A8%E8%AE%BA"><span class="toc-text">结果与讨论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#TOT%E7%9A%84%E5%85%B7%E4%BD%93%E5%AE%9E%E6%96%BD%E8%BF%87%E7%A8%8B%EF%BC%9A"><span class="toc-text">TOT的具体实施过程：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E5%88%86%E8%A7%A3"><span class="toc-text">问题分解</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%9D%E6%83%B3%E7%94%9F%E6%88%90"><span class="toc-text">思想生成</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%8A%B6%E6%80%81%E8%AF%84%E4%BC%B0"><span class="toc-text">状态评估</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95"><span class="toc-text">搜索算法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24%E7%82%B9%E6%B8%B8%E6%88%8F"><span class="toc-text">24点游戏</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E9%80%A0%E6%80%A7%E5%86%99%E4%BD%9C"><span class="toc-text">创造性写作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A1%AB%E8%AF%8D%E6%B8%B8%E6%88%8F"><span class="toc-text">填词游戏</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E7%AB%A0%E4%BC%98%E5%8A%BF"><span class="toc-text">文章优势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E6%88%91%E6%83%B3%E6%B3%95"><span class="toc-text">自我想法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83"><span class="toc-text">思考</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%BE%E8%A1%A8"><span class="toc-text">图表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%A5%E5%BC%8F"><span class="toc-text">句式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Graph-of-Thoughts-Solving-Elaborate-Problems-with-Large-Language-Models"><span class="toc-text">Graph of Thoughts: Solving Elaborate Problems with Large Language Models</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E7%AB%A0%E4%BF%A1%E6%81%AF-1"><span class="toc-text">文章信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF-1"><span class="toc-text">背景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF-2"><span class="toc-text">背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E7%9A%84-1"><span class="toc-text">目的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA-1"><span class="toc-text">结论</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#AUTOMATIC-CHAIN-OF-THOUGHT-PROMPTING-IN-LARGE-LANGUAGE-MODELS"><span class="toc-text">AUTOMATIC CHAIN OF THOUGHT PROMPTING IN LARGE LANGUAGE MODELS</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E7%AB%A0%E4%BF%A1%E6%81%AF-2"><span class="toc-text">文章信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF%EF%BC%88%E9%97%AE%E9%A2%98%EF%BC%89"><span class="toc-text">研究背景（问题）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-text">方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA-2"><span class="toc-text">结论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%EF%BC%88%E5%B1%95%E6%9C%9B%EF%BC%89"><span class="toc-text">思考（展望）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0"><span class="toc-text">学习</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Large-Language-Models-are-Zero-Shot-Reasoners"><span class="toc-text">Large Language Models are Zero-Shot Reasoners</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E7%AB%A0%E4%BF%A1%E6%81%AF-3"><span class="toc-text">文章信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF%EF%BC%88%E9%97%AE%E9%A2%98%EF%BC%89%E5%8F%AF%E4%BB%A5%E4%B8%80%E6%AE%B5%E4%B8%80%E6%AE%B5%E5%86%99"><span class="toc-text">研究背景（问题）可以一段一段写</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-1"><span class="toc-text">方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA-3"><span class="toc-text">结论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-text">实验</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-text">结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%EF%BC%88%E5%B1%95%E6%9C%9B%EF%BC%89-1"><span class="toc-text">思考（展望）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0-1"><span class="toc-text">学习</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Prompt-Engineering%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%9A%E5%AE%A2%E4%BB%A5%E4%B8%8B%E5%86%85%E5%AE%B9%E5%BE%85%E8%A1%A5%E5%85%A8"><span class="toc-text">Prompt Engineering的网络博客以下内容待补全</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Survey%EF%BC%9APre-train-Prompt-and-Predict-A-Systematic-Survey-of-Prompting-Methods-in-Natural-Language-Processing"><span class="toc-text">Survey：Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Training-data-efficient-image-transformers-distillation-through-attention%EF%BC%88backbone%EF%BC%89"><span class="toc-text">Training data-efficient image transformers &amp; distillation through attention（backbone）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF-3"><span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">解决的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-2"><span class="toc-text">方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-text">实验结果</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#AdaptFormer-Adapting-Vision-Transformers-for-Scalable-Visual-Recognition"><span class="toc-text">AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF-4"><span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-3"><span class="toc-text">方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA-4"><span class="toc-text">结论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C-1"><span class="toc-text">实验</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C-1"><span class="toc-text">结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83-1"><span class="toc-text">思考</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#BYOL-Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning"><span class="toc-text">BYOL: Bootstrap Your Own Latent A New Approach to Self-Supervised Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-4"><span class="toc-text">方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA-5"><span class="toc-text">结论</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Exploring-Simple-Siamese-Representation-Learning"><span class="toc-text">Exploring Simple Siamese Representation Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%81%87%E8%AE%BE"><span class="toc-text">假设</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SimCLR%EF%BC%9AA-Simple-Framework-for-Contrastive-Learning-of-Visual-Representations"><span class="toc-text">SimCLR：A Simple Framework for Contrastive Learning of Visual Representations</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-bg" id="search-bg"></div>
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 我与我周旋久,宁作我 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        读点论文
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2024-02-14 23:44:51</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#论文" title="论文">论文</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content no-indent">
        <h1 id="Tree-of-Thoughts-Deliberate-Problem-Solving-with-Large-Language-Models"><a href="#Tree-of-Thoughts-Deliberate-Problem-Solving-with-Large-Language-Models" class="headerlink" title="Tree of Thoughts: Deliberate Problem Solving with Large Language Models"></a>Tree of Thoughts: Deliberate Problem Solving with Large Language Models</h1><h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>2023nips,DeepMind</p>
<h2 id="背景目的及结论"><a href="#背景目的及结论" class="headerlink" title="背景目的及结论"></a>背景目的及结论</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>Input-output (IO) prompting：普通的IO输入输出</p>
<p>Chain-of-thought (CoT) prompting：思维链的输入输出</p>
<p>Self-consistency with CoT (CoT-SC)：自一致性的思维链</p>
<p>但是这些模型没有对于思维过程进行局部探索，并且最频繁的启发式搜索仅在输出空间有限时适用</p>
<p>当前的模型仍然是以从左到右的方式逐一做出token级的决定，这样一个简单的机制是否足以让LM朝着一般问题解决者的方向发展？</p>
<p>研究表明，人有两种参与决策的模式–快速、自动、无意识的模式（”系统1”）和缓慢、慎重、有意识的模式（”系统2”）。</p>
<p>我们想探索系统2：维护和探索当前选择的不同备选方案，而不仅仅是挑选一个；评估当前状态并积极展望未来或回溯以做出更多全局决策。</p>
<h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>生成一种第二种决策模式的方案，把从左到右生成答案的过程给他变成一个在树空间进行搜索的过程</p>
<p>Such a high-level semantic unit allows the LM to self-evaluate the progress different intermediate thoughts make towards solving the problem through a deliberate reasoning process that is also instantiated in language (Figures 2,4,6).</p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>给出了三个自己做的任务，24点，创意写作，填词游戏，分别在这三个游戏中的很好的结果，本质上是通过构建树的过程去达到让模型去思考的结果</p>
<p>这些模型在解决问题时仍然局限于从左至右的决策过程，这意味着它们可能在需要探索、战略预见或需要初步决策扮演重要角色的任务中表现不佳。为了克服这些挑战，论文提出了一个新的语言模型推理框架，名为Tree of Thoughts (ToT)。</p>
<ol>
<li>语言模型推理时局限于token级别、从左到右的决策过程。</li>
<li>本文提出了一个新的语言模型推理框架ToT（Tree of Thoughts，思维树）。</li>
<li>概括了流行的CoT（Chain of Thought，思维链）方法来提示模型，可以探索连贯的文本单元（想法）作为解决问题的中间步骤。</li>
<li>ToT允许模型通过考虑多种不同的推理路径和自我评估选择来执行深思熟虑的决策，并在必要时向前看或回溯以做出全局选择。</li>
</ol>
<p>we propose three new problems that challenge existing LM inference methods even with the state-of-the-art language model, GPT-4 [20]: Game of 24, Creative Writing, and Crosswords (Table 1). These tasks require deductive, mathematical, commonsense, lexical reasoning abilities, and a way to incorporate systematic planning or search. We show ToT obtains superior results on all three tasks by being general and flexible enough to support different levels of thoughts, different ways to generate and evaluate thoughts, and different search algorithms that adapt to the nature of different problems. We also analyze how such choices affect model performances via systematic ablations and discuss future directions to better train and use LMs.</p>
<p>As Figure 1 illustrates, while existing methods (detailed below) sample continuous language sequences for problem solving, ToT actively maintains a tree of thoughts, where each thought is a coherent language sequence that serves as an intermediate step toward problem solving (Table 1). Such a high-level semantic unit allows the LM to self-evaluate the progress different intermediate thoughts make towards solving the problem through a deliberate reasoning process that is also instantiated in language (Figures 2,4,6).</p>
<h2 id="结果与讨论"><a href="#结果与讨论" class="headerlink" title="结果与讨论"></a>结果与讨论</h2><p>结果主要是在作者提出的三个游戏中得到了优于以上提出的三种背景中的提问形式</p>
<h3 id="TOT的具体实施过程："><a href="#TOT的具体实施过程：" class="headerlink" title="TOT的具体实施过程："></a>TOT的具体实施过程：</h3><h4 id="问题分解"><a href="#问题分解" class="headerlink" title="问题分解"></a>问题分解</h4><p>如何将想要的问题分解为合适的中间步骤的子问题是有讲究的，问题不能太大也不能太小，</p>
<h4 id="思想生成"><a href="#思想生成" class="headerlink" title="思想生成"></a>思想生成</h4><p>有两种方式可以生成候选的答案</p>
<ul>
<li>采样<ul>
<li>直接使用大模型进行采样，这种方法更适用于思考空间丰富的情况，例如每个思考点都是一个段落。</li>
</ul>
</li>
<li>提示建议<ul>
<li>使用大模型在建议中进行采样，这种方法在思考空间更受限的情况下效果更好，例如每个思考点只是一个单词或一行。</li>
</ul>
</li>
</ul>
<h4 id="状态评估"><a href="#状态评估" class="headerlink" title="状态评估"></a>状态评估</h4><ul>
<li>打分<ul>
<li>可以给每个状态打分（1-10）</li>
</ul>
</li>
<li>投票<ul>
<li>让模型进行投票对多个答案进行投票</li>
</ul>
</li>
</ul>
<h4 id="搜索算法"><a href="#搜索算法" class="headerlink" title="搜索算法"></a>搜索算法</h4><p>仅使用BFS或DFS</p>
<h3 id="24点游戏"><a href="#24点游戏" class="headerlink" title="24点游戏"></a>24点游戏</h3><p>对于Baselines（I&#x2F;O,CoT）来说，可以使用refine的方法，对于答案进行精炼</p>
<p>对于ToT来说，使用BFS就可以进行搜索了，每次value就行</p>
<h3 id="创造性写作"><a href="#创造性写作" class="headerlink" title="创造性写作"></a>创造性写作</h3><p>ToT:进行BFS，使用5层的宽度，树的第一层可以生成一个写作的计划，对这五个进行投票之后，再去生成五篇文章</p>
<h3 id="填词游戏"><a href="#填词游戏" class="headerlink" title="填词游戏"></a>填词游戏</h3><p>DFS：可以将这个游戏分成字母，单词，和整局游戏的输赢，把DFS中最深的输出给输出出来</p>
<h2 id="文章优势"><a href="#文章优势" class="headerlink" title="文章优势"></a>文章优势</h2><ol>
<li>开头的那个系统一系统二的论述真的是一个好的讲故事的方法</li>
<li>传统的数据结构运用在这个思维构建的过程中，像有个很著名的算法好像就是放在队列里面</li>
<li>任务的选取也很好，问题选的不大不小</li>
<li>设计baseline中对于CoT和IO的设计，包括refine和回溯</li>
</ol>
<h2 id="自我想法"><a href="#自我想法" class="headerlink" title="自我想法"></a>自我想法</h2><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>是不是在考虑基础数据结构在模型中的应用，并且其他算法的思想是不是也是可以运用进来的。并且不止是算法的思想，还可以使用一些其他方面的思想，思路不要被固定住</p>
<h3 id="图表"><a href="#图表" class="headerlink" title="图表"></a>图表</h3><p><img src="http://qiniu-img.pion6.cn//image-20231221164459319.png" alt="image-20231221164459319"></p>
<p><img src="http://qiniu-img.pion6.cn//image-20231221164538536.png" alt="image-20231221164538536"></p>
<p><img src="http://qiniu-img.pion6.cn//image-20231221164553808.png" alt="image-20231221164553808"></p>
<h3 id="句式"><a href="#句式" class="headerlink" title="句式"></a>句式</h3><p>Here we explore 5 × 5 mini crosswords as a harder search problem involving natural language. Again, the goal is not just to solve the task, as more general crosswords can be readily solved with specialized NLP pipelines [31] that leverages large-scale retrieval instead of LM. Rather, we aim to explore the limit of LM as a general problem solver that explores its own thoughts and guides its own exploration with deliberate reasoning as heuristics.</p>
<p>The literature on human cognition provides some clues to answer these questions. Research on “dual process” models suggests that people have two modes in which they engage with decisions – a fast, automatic, unconscious mode (“System 1”) and a slow, deliberate, conscious mode (“System 2”)</p>
<h1 id="Graph-of-Thoughts-Solving-Elaborate-Problems-with-Large-Language-Models"><a href="#Graph-of-Thoughts-Solving-Elaborate-Problems-with-Large-Language-Models" class="headerlink" title="Graph of Thoughts: Solving Elaborate Problems with Large Language Models"></a>Graph of Thoughts: Solving Elaborate Problems with Large Language Models</h1><h2 id="文章信息-1"><a href="#文章信息-1" class="headerlink" title="文章信息"></a>文章信息</h2><p>AAAI2024</p>
<h2 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h2><h3 id="背景-2"><a href="#背景-2" class="headerlink" title="背景"></a>背景</h3><p>生成prompt的方法越来越多，如最近的CoT，cotsc、tot等，但是这些方法都限制了模型在思维过程中的推理能力，对于ToT来说他将整个思维过程限制到了整个树状结构中。而根据我们人脑的一些神经活动，人的推理过程，算法的执行过程来看，更加好的推理过程可以被生成通过使用任意的图结构(arbitrary graph structure),例如，人们可以将以前思维链的想法和现在的想法相结合，而不是直接抛弃他，并且使用他们的优点，消除他们的缺点，以此来形成一个更好的答案。优化一个更加好的推理过程</p>
<h3 id="目的-1"><a href="#目的-1" class="headerlink" title="目的"></a>目的</h3><p>生成一个任意的图状结构，来完成更加复杂的思维过程。并且提出了五个贡献</p>
<h3 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h3><p>在生成的三个问题中得到了SOTA，好像这种方式真的有帮助模型在思维框架下进行思考</p>
<h1 id="AUTOMATIC-CHAIN-OF-THOUGHT-PROMPTING-IN-LARGE-LANGUAGE-MODELS"><a href="#AUTOMATIC-CHAIN-OF-THOUGHT-PROMPTING-IN-LARGE-LANGUAGE-MODELS" class="headerlink" title="AUTOMATIC CHAIN OF THOUGHT PROMPTING IN LARGE LANGUAGE MODELS"></a>AUTOMATIC CHAIN OF THOUGHT PROMPTING IN LARGE LANGUAGE MODELS</h1><h2 id="文章信息-2"><a href="#文章信息-2" class="headerlink" title="文章信息"></a>文章信息</h2><p>2023ICLR；CoT;</p>
<h2 id="研究背景（问题）"><a href="#研究背景（问题）" class="headerlink" title="研究背景（问题）"></a>研究背景（问题）</h2><p>对于CoTSc和CoT来说，对于CoT的构建都是手工的，需要自己针对每一个任务去给出针对性的fewshot的范例，虽然这样的效果很好，但是相对来说是很麻烦的，对于每个任务都要去手动的给出相应的示例，需要自己去挑选示例，并且对于我们的挑选的范例的要求也是一个挑战。</p>
<p>相对于ZeroShot来说，虽然这句话对于每个任务都适用，但是对于每个任务来说效果肯定不如FewShotCoT，可以使用</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h2 id="结论-2"><a href="#结论-2" class="headerlink" title="结论"></a>结论</h2><h2 id="思考（展望）"><a href="#思考（展望）" class="headerlink" title="思考（展望）"></a>思考（展望）</h2><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h1 id="Large-Language-Models-are-Zero-Shot-Reasoners"><a href="#Large-Language-Models-are-Zero-Shot-Reasoners" class="headerlink" title="Large Language Models are Zero-Shot Reasoners"></a>Large Language Models are Zero-Shot Reasoners</h1><h2 id="文章信息-3"><a href="#文章信息-3" class="headerlink" title="文章信息"></a>文章信息</h2><p>nips2022；CoT;</p>
<h2 id="研究背景（问题）可以一段一段写"><a href="#研究背景（问题）可以一段一段写" class="headerlink" title="研究背景（问题）可以一段一段写"></a>研究背景（问题）可以一段一段写</h2><p>主要的研究问题是在LLM背景之下，如何研究prompt成了NLP领域的热门话题。在直观的单步系统system1中LLM表现还不错，但是在一些需要推理的问题System2中，表现的不是很尽如人意。但是在FewShot CoT出现之后这个问题可以说得到了显著的改善。但是FewshotCoT中还只是相对于特定任务，对于一些需要推理的相对于广泛的下游任务还是无法尽到作用。第二，还有缩放scaling laws的任务，第三给以后的任务提供一个基线。</p>
<h2 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h2><p>实验过程相当简单，这边给了两个步骤，第一步是把问题和生成思维链的提示句进行了拼接，第二步是把第一步的整个提问和答案拼接，再加一个抽取答案的提示就形成了答案抽取的提示。</p>
<h2 id="结论-3"><a href="#结论-3" class="headerlink" title="结论"></a>结论</h2><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>实验给出了ZeroShotCoT在12个数据集上的实验结果。试验所使用的模型分别是GPT系列和PaLM系列。实验还添加了</p>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>结果是ZSCoT实验结果远远大于ZS。个人理解：因为推理的作用，生成答案的结果使得大模型思考的时间变长了，所以生成的结果更加的准确了。&#x3D;&#x3D;并且对于一些不太正确的结果来说，其实有些推理过程也是正确的。&#x3D;&#x3D;说明这个推理的过程确实是有用的。</p>
<p>对于CoT来说，对于大模型的效果要远大于小模型，&#x3D;&#x3D;难道这就是所说的缩放定律吗&#x3D;&#x3D;</p>
<p>并且下面还有一段话，”如果给出的提示和所要解答的问题格式不对应的话，那么效果会很差，意思是大模型是按图索骥，仅仅是按照给定的问题的过程去进行套用吗”</p>
<blockquote>
<p>In contrast, the performance gain becomes much less when using examples with different answer types (to MultiArith), confirming prior work [Min et al., 2022] that suggests LLMs mostly leverage the few-shot examples to infer the repeated format rather than the task itself in-context. Nevertheless, for both cases the results are worse than Zero-shot-CoT, affirming the importance of task-specific sample engineering in Few-shot-CoT.</p>
</blockquote>
<h2 id="思考（展望）-1"><a href="#思考（展望）-1" class="headerlink" title="思考（展望）"></a>思考（展望）</h2><ul>
<li>作者说错误的fewshot格式会影响最终结果的正确性，我在如果给出的示例的答案格式不一样，那么答错是很正常的吧，我不太懂</li>
</ul>
<blockquote>
<p>In contrast, the performance gain becomes much less when using examples with different answer types (to MultiArith), confirming prior work [Min et al., 2022] that suggests LLMs mostly leverage the few-shot examples to infer the repeated format rather than the task itself in-context. Nevertheless, for both cases the results are worse than Zero-shot-CoT, affirming the importance of task-specific sample engineering in Few-shot-CoT.</p>
</blockquote>
<ul>
<li>难道这种特定的格式的prompt是一定要在大模型中才能使用的吗，如果小一些的模型就不能通过类似prompt的方式来增加思考的过程（或者说思考的时间边变长的方式来增加思考的准确性的），对于多模态的工作也是同理</li>
</ul>
<h2 id="学习-1"><a href="#学习-1" class="headerlink" title="学习"></a>学习</h2><p><img src="http://qiniu-img.pion6.cn//image-20240103113713277.png" alt="image-20240103113713277"></p>
<blockquote>
<p>We compare our Zero-shot-CoT mainly to standard Zero-shot prompting to verify the effectiveness of its chain of thought reasoning.</p>
</blockquote>
<blockquote>
<p>Our simple method not only is the minimalist and strongest zero-shot baseline for difficult multi-step system-2 reasoning tasks that long evaded the scaling laws of LLMs, but also encourages the community to further discover similar multi-task prompts that elicit broad cognitive abilities instead of narrow task-specific skills.</p>
</blockquote>
<blockquote>
<p>We have proposed Zero-shot-CoT, a single zero-shot prompt that elicits chain of thought from large language models across a variety of reasoning tasks, in contrast to the few-shot (in-context) approach in previous work that requires hand-crafting few-shot examples per task.</p>
</blockquote>
<h1 id="Prompt-Engineering的网络博客以下内容待补全"><a href="#Prompt-Engineering的网络博客以下内容待补全" class="headerlink" title="Prompt Engineering的网络博客以下内容待补全"></a>Prompt Engineering的网络博客以下内容待补全</h1><p>2024.02.10</p>
<p>好多论文都没听说过</p>
<p><a href="https://lilianweng.github.io/">Lil’Log </a></p>
<p><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/">Prompt Engineering</a></p>
<ul>
<li>Basic Prompting<ul>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#zero-shot">Zero-Shot</a></li>
<li>Few-shot<ul>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#tips-for-example-selection">&#x3D;&#x3D;Tips for Example Selection&#x3D;&#x3D;</a></li>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#tips-for-example-ordering">Tips for Example Ordering</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#instruction-prompting">Instruction Prompting</a></li>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#self-consistency-sampling">Self-Consistency Sampling</a></li>
<li>Chain-of-Thought (CoT)<ul>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#types-of-cot-prompts">Types of CoT prompts</a></li>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#tips-and-extensions">Tips and Extensions</a></li>
</ul>
</li>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#automatic-prompt-design">Automatic Prompt Design</a></li>
<li>Augmented Language Models<ul>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#retrieval">Retrieval</a></li>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#programming-language">Programming Language</a></li>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#external-apis">External APIs</a></li>
</ul>
</li>
</ul>
<h1 id="Survey：Pre-train-Prompt-and-Predict-A-Systematic-Survey-of-Prompting-Methods-in-Natural-Language-Processing"><a href="#Survey：Pre-train-Prompt-and-Predict-A-Systematic-Survey-of-Prompting-Methods-in-Natural-Language-Processing" class="headerlink" title="Survey：Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"></a>Survey：Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</h1><p>主要是介绍了NLP的发展脉络，从特征工程到目标工程，再到提示工程</p>
<p>我觉得最重要的图片是下面几张</p>
<p><img src="http://qiniu-img.pion6.cn//image-20240220174557268.png" alt="image-20240220174557268"></p>
<p><img src="http://qiniu-img.pion6.cn//image-20240220174720803.png" alt="image-20240220174720803"></p>
<p><img src="http://qiniu-img.pion6.cn//image-20240220174743450.png" alt="image-20240220174743450"></p>
<h1 id="Training-data-efficient-image-transformers-distillation-through-attention（backbone）"><a href="#Training-data-efficient-image-transformers-distillation-through-attention（backbone）" class="headerlink" title="Training data-efficient image transformers &amp; distillation through attention（backbone）"></a>Training data-efficient image transformers &amp; distillation through attention（backbone）</h1><blockquote>
<p>泛读，<a href="https://www.bilibili.com/video/BV1L5411P7rV">https://www.bilibili.com/video/BV1L5411P7rV</a></p>
<p>backbone</p>
</blockquote>
<h2 id="背景-3"><a href="#背景-3" class="headerlink" title="背景"></a>背景</h2><p>ViT训练数据太大，并且数据集不开源，训练困难</p>
<h2 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h2><ul>
<li>训练数据仅用ImageNet</li>
<li>8*V100比较小的资源</li>
<li>基于token进行蒸馏</li>
</ul>
<h2 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h2><p>不同的损失函数</p>
<p><img src="http://qiniu-img.pion6.cn//image-20240304112636338.png" alt="image-20240304112636338"></p>
<p>使用一个CLStoken和蒸馏token。训练的时候蒸馏token和teacher的结果进行计算损失，CLS和GT计算损失。预测的时候两边乘以0.5进行计算最终预测结果</p>
<p><img src="http://qiniu-img.pion6.cn//%5B%E8%AE%BA%E6%96%87%E7%AE%80%E6%9E%90%5DDeiT_%20Data-efficient%20Image%20Transformers%5B2012.12877%5D_%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9_bilibili_5'19.924''.jpg" alt="[论文简析]DeiT_ Data-efficient Image Transformers[2012.12877]_哔哩哔哩_bilibili_5&#39;19.924&#39;&#39;"></p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>自己看不贴了</p>
<h1 id="AdaptFormer-Adapting-Vision-Transformers-for-Scalable-Visual-Recognition"><a href="#AdaptFormer-Adapting-Vision-Transformers-for-Scalable-Visual-Recognition" class="headerlink" title="AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition"></a>AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition</h1><blockquote>
<p>附加结构型PEFT</p>
<p>NeurIPS, 2022</p>
</blockquote>
<h2 id="背景-4"><a href="#背景-4" class="headerlink" title="背景"></a>背景</h2><p>这篇文章在VPT之后，他觉得VPT那种形式对于一些长输入token的tansformer模型效果不好，而且不具备普适性</p>
<ul>
<li>VPT那种形式对于一些长输入token的tansformer模型效果不好</li>
<li>不具备普适性</li>
<li>VPT学到的内容不能很好的做迁移</li>
</ul>
<h2 id="方法-3"><a href="#方法-3" class="headerlink" title="方法"></a>方法</h2><ul>
<li><p>对transformer中的编码器结构的MLP，做了并行的结构,公式如下</p>
</li>
<li><p>而且这个$W_{down}$是把$x$从大变小，而$W_{up}$是从小变大中间有个$Relu$函数</p>
</li>
<li><p>下面还陈述了并行结构的很多好处</p>
<p><img src="http://qiniu-img.pion6.cn//image-20240305113114036.png" alt="image-20240305113114036"><br>$$<br>\widetilde{x}<em>l &#x3D; ReLU(LN(x^&#96;<em>l) · W</em>{down}) · W</em>{up}.<br>$$</p>
<p>$$<br>x &#x3D; MLP(LN(x_l^<code>)) + s · \widetilde&#123;x&#125;_l + x_l^</code><br>$$</p>
</li>
</ul>
<h2 id="结论-4"><a href="#结论-4" class="headerlink" title="结论"></a>结论</h2><h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><ul>
<li>和finetune作对比，而且作对比的时候肯定是不如finetune的</li>
<li>和VPT作对比</li>
</ul>
<h3 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h3><p>(1)我们提出了一个简单而有效的框架，即AdaptFormer，用于使视觉转换器适应大量的下游视觉识别任务，并避免彼此之间的灾难性干扰。据我们所知，这是第一个探索视频动作识别中高效微调的工作。</p>
<p>(2)我们排除了许多设计选择，并展示了AdaptFormer在参数放大时的卓越健壮性。</p>
<p>(3)在不同下游任务上的广泛实验表明，AdaptFormer的性能明显优于现有的微调方法。通过展示AdaptFormer在多个视觉基准上的有效性，我们希望我们的工作可以启发研究团体重新思考计算机视觉中的微调机制，并朝着灵活而通用的视觉识别Transformer模型迈进。</p>
<h2 id="思考-1"><a href="#思考-1" class="headerlink" title="思考"></a>思考</h2><p>这篇文章主要是提供了一个向transformer中添加了一个适配器结构，结果中了nips</p>
<p>这篇文章主要说的是在视频资源中，这类长token序列中添加了这个适配器结构，注意token长度也是一个可创新的点，我划线了</p>
<p>文章中还谈到了并行结构的设计的原因，已划线，这下面这两篇可以读一读，如果有空的话</p>
<blockquote>
<p>Going deeper with convolutions.</p>
<p>Attention is not all you need: Pure attention loses rank doubly exponentially with depth.</p>
</blockquote>
<p>关于如何进行参数初始化感觉也可以学一学4.1</p>
<p>并且和VPT进行可调参数增加实验的对比方法可以学一学4.3</p>
<p>还有参数的迁移不会特别影响下游任务（喜欢对比？）4.6</p>
<p>t-SNE 可视化4.7</p>
<p><img src="http://qiniu-img.pion6.cn//image-20240305121733709.png" alt="image-20240305121733709"></p>
<h1 id="BYOL-Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning"><a href="#BYOL-Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning" class="headerlink" title="BYOL: Bootstrap Your Own Latent A New Approach to Self-Supervised Learning"></a>BYOL: Bootstrap Your Own Latent A New Approach to Self-Supervised Learning</h1><blockquote>
<p>泛读：<a href="https://www.bilibili.com/video/BV1ki4y1T7X4">https://www.bilibili.com/video/BV1ki4y1T7X4</a></p>
<p>是使用自监督的方式进行的pretrained-model，backbone</p>
</blockquote>
<h2 id="方法-4"><a href="#方法-4" class="headerlink" title="方法"></a>方法</h2><p>流程如下：</p>
<ol>
<li>对同一张图片进行不同的图像增强操作</li>
<li>输入到online模型和target模型中（这两个模型的除了最后一步中模型结构不同，其他的结构都完全相同，参数的话online模型的更新应该是先于target模型的）</li>
<li>online模型中的结果经过了prediction之后，和target进行计算loss（我的理解是，因为t和t’有区别所以prediction用来弭平这个差距，最终使用这个loss更新online模型，target模型随后跟着online进行更新）</li>
<li>使这两个模型尽量靠近，但又不完全一样</li>
</ol>
<p><img src="http://qiniu-img.pion6.cn//BYol1.jpg" alt="BYol1"></p>
<p><img src="http://qiniu-img.pion6.cn//BYOL2.jpg" alt="BYOL2"></p>
<h2 id="结论-5"><a href="#结论-5" class="headerlink" title="结论"></a>结论</h2><p>我觉得方法有点像左右互搏术</p>
<p><img src="http://qiniu-img.pion6.cn//image-20240305111401541.png" alt="image-20240305111401541"></p>
<h1 id="Exploring-Simple-Siamese-Representation-Learning"><a href="#Exploring-Simple-Siamese-Representation-Learning" class="headerlink" title="Exploring Simple Siamese Representation Learning"></a>Exploring Simple Siamese Representation Learning</h1><blockquote>
<p><a href="https://arxiv.org/abs/2011.10566">https://arxiv.org/abs/2011.10566</a></p>
<p><a href="https://www.bilibili.com/video/BV1Ah411Q7Lb">https://www.bilibili.com/video/BV1Ah411Q7Lb</a></p>
<p>孪生网络的类似EM算法假设</p>
</blockquote>
<h2 id="假设"><a href="#假设" class="headerlink" title="假设"></a>假设</h2><p>这篇最重要的贡献就是提出了一种使用EM算法去解释孪生网络的假设</p>
<p>我们假设有以下的损失函数，总的来说是一个类似余弦相似度的，$\mathcal{T}$为图像增强函数，$\theta$为模型参数，$\eta_x$为图像对应的表征，可以把它理解为其中停止梯度的模型给出的对于图像的表征。<br>$$<br>\mathcal{L}(\theta,\eta)&#x3D;\mathbb{E}_{x,\mathcal{T}}\Big[\left|\mathcal{F}_\theta(\mathcal{T}(x))-\eta_x\right|_2^2\Big].<br>$$<br>在上述进行假设之后，我们可以根据EM算法给出优化过程</p>
<ul>
<li><p>对于优化$\theta$的过程，我们可以通过停止$\eta^{t-1}$的参数更新进行，也就是我上面提到的停止梯度的模型，因为EM算法一次只能更新一个参数。但是对于$\theta$更新的是那个左边的模型，也就是可以更新参数的那个模型</p>
</li>
<li><p>下面公式中的$\eta$其实就是相当于使用更新好模型参数的对于图片表征进行一次更新</p>
</li>
</ul>
<p>$$<br>\theta^t\leftarrow\arg\min_\theta\mathcal{L}(\theta,\eta^{t-1})(7)\<br>\eta^t\leftarrow\arg\min_\eta~\mathcal{L}(\theta^t,\eta)(8)<br>$$</p>
<p>对于8式我们可以这样做近似，具体原因可以看论文<br>$$<br>\eta_x^t\leftarrow\mathcal{F}<em>{\theta^t}(\mathcal{T}^{\prime}(x))(10).<br>$$<br>代入7式，可得以下式子<br>$$<br>\theta^{t+1}\leftarrow\arg\min_\theta\mathbb{E}</em>{x,\mathcal{T}}\Big[\left|\mathcal{F}<em>\theta(\mathcal{T}(x))-\mathcal{F}</em>{\theta^t}(\mathcal{T}^{\prime}(x))\right|_2^2\Big]<br>$$<br>别忘记还有个Predictor，这个predictor其实是可以尽量去缩小之前我们在10式中的近似的影响的</p>
<p>这个假设是很重要的</p>
<h1 id="SimCLR：A-Simple-Framework-for-Contrastive-Learning-of-Visual-Representations"><a href="#SimCLR：A-Simple-Framework-for-Contrastive-Learning-of-Visual-Representations" class="headerlink" title="SimCLR：A Simple Framework for Contrastive Learning of Visual Representations"></a>SimCLR：A Simple Framework for Contrastive Learning of Visual Representations</h1><blockquote>
<p><a href="http://arxiv.org/abs/2002.05709">http://arxiv.org/abs/2002.05709</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/378953015">https://zhuanlan.zhihu.com/p/378953015</a></p>
<p>其实和其他孪生网络相比感觉基本上没啥变化</p>
</blockquote>
<p><img src="http://qiniu-img.pion6.cn//image-20240308151520728.png" alt="image-20240308151520728"></p>
<p>其实和其他孪生网络相比感觉基本上没啥变化，感觉主要是变了损失函数，以及引入了负样本。分子中的式子是同一张图片的不同变换所做的相似度内容。分母中的内容是同一批次中和其他内容做相似度的值的求和，最终按照这个式子求损失。<br>$$<br>\ell_{i,j}&#x3D;-\log\frac{\exp(\sin(\boldsymbol{z}<em>i,\boldsymbol{z}<em>j)&#x2F;\tau)}{\sum</em>{k&#x3D;1}^{2N}\mathbb{1}</em>{[k\neq i]}\exp(\sin(\boldsymbol{z}_i,\boldsymbol{z}_k)&#x2F;\tau)}<br>$$</p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>
        <div id="lv-container"></div>
        <div class="giscus"></div>
    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        
        <li>
            <a target="_blank"  href="https://github.com/Pion6">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-github"></i>
                            </span>
            </a>
        </li>
        

        

    </ul>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

<script src="/js/index.js"></script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




    <script src="https://giscus.app/client.js"
    data-repo="aircloud/hexo-aircloud-blog"
    data-repo-id="MDEwOlJlcG9zaXRvcnkxMjkwNDgyNjg="
    data-category="Announcements"
    data-category-id="DIC_kwDOB7EezM4COhKJ"
    data-mapping="title"
    data-reactions-enabled="1"
    data-emit-metadata="0"
    data-input-position="bottom"
    data-theme="light"
    data-lang="zh-CN"
    crossorigin="anonymous"
    async>
</script>




</html>
